import numpy as np
import matplotlib.pyplot as plt

def mean_squared_error(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

def gradient_descent(x, y, iterations=1000, learning_rate=0.0001, tol=1e-6):
    weight, bias = 0.1, 0.01
    n = len(x)
    prev_cost = float('inf')

    for _ in range(iterations):
        y_pred = weight * x + bias
        cost = mean_squared_error(y, y_pred)
        
        if abs(prev_cost - cost) < tol:
            break
        prev_cost = cost

        weight -= learning_rate * (-2/n * np.sum(x * (y - y_pred)))
        bias -= learning_rate * (-2/n * np.sum(y - y_pred))

    return weight, bias

def main():
    X = np.array([52.5, 63.4, 81.5, 47.5, 89.8, 55.1, 52.2, 39.3, 48.1, 52.6, 45.4, 54.4, 44.2, 58.2, 56.7, 49.0, 44.7, 60.3, 45.6, 38.8])
    Y = np.array([41.7, 78.8, 82.6, 91.5, 77.2, 78.2, 79.6, 59.2, 75.3, 71.3, 55.2, 82.5, 62.0, 75.4, 81.4, 60.7, 82.9, 97.4, 48.8, 56.9])
    
    weight, bias = gradient_descent(X, Y, iterations=2000)
    print(f"Weight: {weight:.4f}, Bias: {bias:.4f}")
    
    plt.scatter(X, Y, color='pink')
    plt.plot(X, weight * X + bias, color='blue', linestyle='--')
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.title("Linear Regression")
    plt.show()

if __name__ == "__main__":
    main()
