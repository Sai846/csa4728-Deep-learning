import numpy as np
import matplotlib.pyplot as plt

def mean_squared_error(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

def gradient_descent(x, y, iterations=1000, learning_rate=0.0001, stopping_threshold=1e-6):
    weight, bias = 0.1, 0.01
    n = len(x)
    costs, weights = [], []
    
    for i in range(iterations):
        y_pred = weight * x + bias
        cost = mean_squared_error(y, y_pred)
        
        if i > 0 and abs(costs[-1] - cost) < stopping_threshold:
            break
        
        costs.append(cost)
        weights.append(weight)
        
        weight -= learning_rate * (-2 * np.sum(x * (y - y_pred)) / n)
        bias -= learning_rate * (-2 * np.sum(y - y_pred) / n)
        
        if (i + 1) % 100 == 0:
            print(f"Iteration {i+1}: Cost {cost:.6f}, Weight {weight:.4f}, Bias {bias:.4f}")

    plt.plot(weights, costs, 'o-', color='red')
    plt.title("Cost vs Weights")
    plt.xlabel("Weight")
    plt.ylabel("Cost")
    plt.show()
    
    return weight, bias

def main():
    X = np.array([32.5, 53.4, 61.5, 47.5, 59.8, 55.1, 52.2, 39.3, 48.1, 52.6, 45.4, 54.4, 44.2, 58.2, 56.7, 49.0, 44.7, 60.3, 45.6, 38.8])
    Y = np.array([31.7, 68.8, 62.6, 71.5, 87.2, 78.2, 79.6, 59.2, 75.3, 71.3, 55.2, 82.5, 62.0, 75.4, 81.4, 60.7, 82.9, 97.4, 48.8, 56.9])
    
    weight, bias = gradient_descent(X, Y, iterations=2000)
    print(f"Estimated Weight: {weight:.4f}\nEstimated Bias: {bias:.4f}")
    
    Y_pred = weight * X + bias
    plt.scatter(X, Y, color='red', label='Data points')
    plt.plot(X, Y_pred, color='blue', linestyle='--', label='Regression line')
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.title("Linear Regression")
    plt.legend()
    plt.show()

if __name__ == "__main__":
    main()
